{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb392-35ff-4bb8-b05f-44afb0a0be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from pathlib import Path\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import euclidean\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9227c1-7a94-4466-a491-5c96f900ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = Path(\"Data/INCLUDE/Society/Videos\")\n",
    "landmark_dir = Path(\"Data/INCLUDE/Society/Landmarks\")\n",
    "\n",
    "#Create same class named folder in Landmark directory \n",
    "class_names = []\n",
    "# Use .iterdir() to loop through the contents of the directory\n",
    "for item in video_dir.iterdir():\n",
    "    # Check if the item is a directory before adding its name\n",
    "    if item.is_dir():\n",
    "        class_names.append(item.name)\n",
    "        \n",
    "# Loop through your list of names and create a new folder for each\n",
    "for name in class_names:\n",
    "    # Construct the full path for the new folder\n",
    "    new_folder_path = os.path.join(landmark_dir, name)\n",
    "    \n",
    "    # Create the directory. exist_ok=True prevents an error if it already exists.\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "print(\"‚úÖ Folders created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9e7e0-548e-461b-801c-56c9f4498d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals to store expected face landmark count\n",
    "EXPECTED_FACE_LANDMARKS = None\n",
    "\n",
    "class AdvancedFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.hand_landmarks = 21\n",
    "        self.face_landmarks = 468\n",
    "        \n",
    "    def extract_hand_features(self, hand_landmarks):\n",
    "        \"\"\"Extract advanced hand features including velocity and acceleration\"\"\"\n",
    "        if hand_landmarks.shape[0] == 0:\n",
    "            return np.zeros(126)  # 42*3 features (basic + velocity + acceleration)\n",
    "            \n",
    "        features = []\n",
    "        \n",
    "        # Basic statistics\n",
    "        features.extend([\n",
    "            np.mean(hand_landmarks, axis=0),\n",
    "            np.std(hand_landmarks, axis=0),\n",
    "            np.min(hand_landmarks, axis=0),\n",
    "            np.max(hand_landmarks, axis=0)\n",
    "        ])\n",
    "        \n",
    "        # Velocity features (frame-to-frame differences)\n",
    "        if hand_landmarks.shape[0] > 1:\n",
    "            velocities = np.diff(hand_landmarks, axis=0)\n",
    "            features.extend([\n",
    "                np.mean(velocities, axis=0),\n",
    "                np.std(velocities, axis=0),\n",
    "            ])\n",
    "        else:\n",
    "            features.extend([np.zeros(42), np.zeros(42)])\n",
    "            \n",
    "        return np.concatenate(features)\n",
    "    \n",
    "    def extract_inter_hand_features(self, right_hand, left_hand):\n",
    "        \"\"\"Extract features between hands\"\"\"\n",
    "        if right_hand.shape[0] == 0 or left_hand.shape[0] == 0:\n",
    "            return np.zeros(6)\n",
    "            \n",
    "        # Reshape to (frames, 21, 2) for proper centroid calculation\n",
    "        right_reshaped = right_hand.reshape(-1, 21, 2)\n",
    "        left_reshaped = left_hand.reshape(-1, 21, 2)\n",
    "        \n",
    "        # Distance between hand centroids over time\n",
    "        right_centroid = np.mean(right_reshaped, axis=1)\n",
    "        left_centroid = np.mean(left_reshaped, axis=1)\n",
    "        \n",
    "        distances = [euclidean(r, l) for r, l in zip(right_centroid, left_centroid)]\n",
    "        \n",
    "        features = [\n",
    "            np.mean(distances),\n",
    "            np.std(distances),\n",
    "            np.min(distances),\n",
    "            np.max(distances)\n",
    "        ]\n",
    "        \n",
    "        # Relative hand positions\n",
    "        relative_positions = right_centroid - left_centroid\n",
    "        features.extend([\n",
    "            np.mean(relative_positions, axis=0),\n",
    "            np.std(relative_positions, axis=0)\n",
    "        ])\n",
    "        \n",
    "        return np.concatenate(features)\n",
    "\n",
    "def extract_frame_landmarks(results):\n",
    "    global EXPECTED_FACE_LANDMARKS\n",
    "    lm = []\n",
    "    \n",
    "    # Right hand (21 points √ó x,y)\n",
    "    if results.right_hand_landmarks:\n",
    "        for p in results.right_hand_landmarks.landmark:\n",
    "            lm.extend([p.x, p.y])\n",
    "    else:\n",
    "        lm.extend([0] * 42)\n",
    "        \n",
    "    # Left hand\n",
    "    if results.left_hand_landmarks:\n",
    "        for p in results.left_hand_landmarks.landmark:\n",
    "            lm.extend([p.x, p.y])\n",
    "    else:\n",
    "        lm.extend([0] * 42)\n",
    "        \n",
    "    # Face landmarks\n",
    "    face_lms = results.face_landmarks.landmark if results.face_landmarks else []\n",
    "    count = len(face_lms)\n",
    "    if EXPECTED_FACE_LANDMARKS is None:\n",
    "        EXPECTED_FACE_LANDMARKS = count or 468\n",
    "        \n",
    "    for i in range(min(count, EXPECTED_FACE_LANDMARKS)):\n",
    "        p = face_lms[i]\n",
    "        lm.extend([p.x, p.y])\n",
    "        \n",
    "    missing = EXPECTED_FACE_LANDMARKS - min(count, EXPECTED_FACE_LANDMARKS)\n",
    "    if missing > 0:\n",
    "        lm.extend([0.0, 0.0] * missing)\n",
    "    \n",
    "    # Final consistency check\n",
    "    total_features = 42 * 2 + EXPECTED_FACE_LANDMARKS * 2\n",
    "    if len(lm) != total_features:\n",
    "        raise ValueError(f\"Inconsistent landmark length {len(lm)} vs expected {total_features}\")\n",
    "    return np.array(lm, dtype=np.float32)\n",
    "\n",
    "def extract_advanced_features_from_sequence(sequence):\n",
    "    \"\"\"Extract advanced features from a landmark sequence\"\"\"\n",
    "    feature_extractor = AdvancedFeatureExtractor()\n",
    "    \n",
    "    # Split sequence into components\n",
    "    right_hand = sequence[:, :42]\n",
    "    left_hand = sequence[:, 42:84]\n",
    "    face = sequence[:, 84:]\n",
    "    \n",
    "    # Basic statistical features\n",
    "    basic_features = np.concatenate([\n",
    "        sequence.mean(axis=0),\n",
    "        sequence.std(axis=0),\n",
    "        sequence.min(axis=0),\n",
    "        sequence.max(axis=0)\n",
    "    ])\n",
    "    \n",
    "    # Advanced hand features\n",
    "    right_hand_features = feature_extractor.extract_hand_features(right_hand)\n",
    "    left_hand_features = feature_extractor.extract_hand_features(left_hand)\n",
    "    \n",
    "    # Inter-hand features\n",
    "    inter_hand_features = feature_extractor.extract_inter_hand_features(right_hand, left_hand)\n",
    "    \n",
    "    # Temporal features\n",
    "    temporal_features = []\n",
    "    if sequence.shape[0] > 1:\n",
    "        # Total variation (movement energy)\n",
    "        total_variation = np.sum(np.abs(np.diff(sequence, axis=0)))\n",
    "        temporal_features.append(total_variation)\n",
    "        \n",
    "        # Sequence length (normalized)\n",
    "        temporal_features.append(sequence.shape[0] / 200.0)\n",
    "    else:\n",
    "        temporal_features.extend([0, 0])\n",
    "    \n",
    "    # Statistical shape features\n",
    "    statistical_features = []\n",
    "    try:\n",
    "        statistical_features.extend([\n",
    "            stats.skew(sequence, axis=0).mean(),  # Average skewness\n",
    "            stats.kurtosis(sequence, axis=0).mean(),  # Average kurtosis\n",
    "        ])\n",
    "    except:\n",
    "        statistical_features.extend([0, 0])\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = np.concatenate([\n",
    "        basic_features,\n",
    "        right_hand_features,\n",
    "        left_hand_features,\n",
    "        inter_hand_features,\n",
    "        temporal_features,\n",
    "        statistical_features\n",
    "    ])\n",
    "    \n",
    "    return all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf0a6f-562a-4e66-836a-93c55d0cfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_dir, landmark_dir, holistic_model):\n",
    "    for file in os.listdir(video_dir):\n",
    "        if not file.lower().endswith((\".avi\", \".mp4\", \".mov\")):\n",
    "            continue\n",
    "            \n",
    "        video_path = os.path.join(video_dir, file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames_lm = []\n",
    "    \n",
    "        print(f\"Processing {file}...\")\n",
    "        frame_count = 0\n",
    "    \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic_model.process(rgb_frame)\n",
    "            \n",
    "            frame_landmarks = extract_frame_landmarks(results)\n",
    "            frames_lm.append(frame_landmarks)\n",
    "            frame_count += 1\n",
    "    \n",
    "        cap.release()\n",
    "        \n",
    "        if frames_lm:\n",
    "            sequence = np.stack(frames_lm, axis=0)\n",
    "            out_file = os.path.join(landmark_dir, file.rsplit(\".\", 1)[0] + \".npy\")\n",
    "            np.save(out_file, sequence)\n",
    "            print(f\"Saved landmarks to {out_file} with shape {sequence.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd24b5-7422-4df3-865e-a67ac695dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_advanced(data_root):\n",
    "    \"\"\"Load data with advanced feature extraction\"\"\"\n",
    "    X, y = [], []\n",
    "    feature_sizes = {}\n",
    "    \n",
    "    for category_folder in Path(data_root).iterdir():\n",
    "        landmarks_root = category_folder / \"Landmarks\"\n",
    "        if not landmarks_root.exists():\n",
    "            continue\n",
    "            \n",
    "        for sign_folder in landmarks_root.iterdir():\n",
    "            if not sign_folder.is_dir():\n",
    "                continue\n",
    "                \n",
    "            for npy_path in sign_folder.glob(\"*.npy\"):\n",
    "                try:\n",
    "                    seq = np.load(npy_path)\n",
    "                    if seq.shape[0] == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Track feature dimensions\n",
    "                    feature_dim = seq.shape[1]\n",
    "                    if feature_dim not in feature_sizes:\n",
    "                        feature_sizes[feature_dim] = 0\n",
    "                    feature_sizes[feature_dim] += 1\n",
    "                    \n",
    "                    # Extract advanced features\n",
    "                    advanced_features = extract_advanced_features_from_sequence(seq)\n",
    "                    \n",
    "                    X.append(advanced_features)\n",
    "                    y.append(sign_folder.name)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {npy_path}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    print(f\"Feature dimension distribution: {feature_sizes}\")\n",
    "    print(f\"Loaded {len(X)} samples with {len(X[0]) if X else 0} features each\")\n",
    "    \n",
    "    return np.vstack(X) if X else np.array([]), np.array(y)\n",
    "\n",
    "def augment_data(X, y, augmentation_factor=1):\n",
    "    \"\"\"Augment data by adding noise\"\"\"\n",
    "    X_aug, y_aug = [], []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X_aug.append(X[i])\n",
    "        y_aug.append(y[i])\n",
    "        \n",
    "        # Add noisy versions\n",
    "        for _ in range(augmentation_factor):\n",
    "            noise = np.random.normal(0, 0.01, X[i].shape)\n",
    "            X_aug.append(X[i] + noise)\n",
    "            y_aug.append(y[i])\n",
    "            \n",
    "    return np.vstack(X_aug), np.array(y_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88d22d-e1ac-4c9b-88ff-32c7b885bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "#                         AUTOMATION CELL TO PROCESS ALL CLASSES\n",
    "# =====================================================================================\n",
    "\n",
    "BASE_VIDEO_PATH = video_dir\n",
    "BASE_LANDMARK_PATH = landmark_dir\n",
    "\n",
    "try:\n",
    "    class_folders = [d for d in BASE_VIDEO_PATH.iterdir() if d.is_dir()]\n",
    "    class_names = [d.name for d in class_folders]\n",
    "    print(f\"‚úÖ Found {len(class_names)} classes: {class_names}\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: The directory '{BASE_VIDEO_PATH}' was not found.\")\n",
    "    class_folders = []\n",
    "\n",
    "class_averages = {}\n",
    "\n",
    "# Process videos to landmarks\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    smooth_landmarks=True,\n",
    "    refine_face_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as holistic:\n",
    "    \n",
    "    for class_dir in class_folders:\n",
    "        class_name = class_dir.name\n",
    "        print(f\"================== Processing Class: {class_name} ==================\")\n",
    "        \n",
    "        video_dir_for_class = class_dir\n",
    "        landmark_dir_for_class = BASE_LANDMARK_PATH / class_name\n",
    "        \n",
    "        os.makedirs(landmark_dir_for_class, exist_ok=True)\n",
    "        process_video(video_dir_for_class, landmark_dir_for_class, holistic)\n",
    "        \n",
    "        try:\n",
    "            file_list = [f for f in os.listdir(landmark_dir_for_class) if f.endswith(\".npy\")]\n",
    "            if file_list:\n",
    "                frame_counts = [np.load(os.path.join(landmark_dir_for_class, f)).shape[0] for f in file_list]\n",
    "                average_frame_count = np.mean(frame_counts)\n",
    "                class_averages[class_name] = average_frame_count\n",
    "                print(f\"‚úÖ Finished processing class '{class_name}' - Avg frames: {average_frame_count:.1f}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error calculating average for '{class_name}': {e}\\n\")\n",
    "\n",
    "print(\"========================================================\")\n",
    "print(\"                    üìä FINAL SUMMARY                    \")\n",
    "print(\"========================================================\")\n",
    "for class_name, avg_frames in sorted(class_averages.items()):\n",
    "    print(f\"  ‚ñ∂Ô∏è  Class '{class_name}': {avg_frames:.2f} average frames\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (signenv)",
   "language": "python",
   "name": "signenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
